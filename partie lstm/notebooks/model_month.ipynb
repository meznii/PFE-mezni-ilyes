{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "personal-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "female-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../datasets/archive_en_p_heur.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ordered-factor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_device</th>\n",
       "      <th>date</th>\n",
       "      <th>en_L1</th>\n",
       "      <th>cons_en_L1</th>\n",
       "      <th>en_L2</th>\n",
       "      <th>cons_en_L2</th>\n",
       "      <th>en_L3</th>\n",
       "      <th>cons_en_L3</th>\n",
       "      <th>en_L4</th>\n",
       "      <th>cons_en_L4</th>\n",
       "      <th>...</th>\n",
       "      <th>min_THD_L4</th>\n",
       "      <th>max_THD_L4</th>\n",
       "      <th>moy_THD_L4</th>\n",
       "      <th>min_THD_L5</th>\n",
       "      <th>max_THD_L5</th>\n",
       "      <th>moy_THD_L5</th>\n",
       "      <th>min_THD_L6</th>\n",
       "      <th>max_THD_L6</th>\n",
       "      <th>moy_THD_L6</th>\n",
       "      <th>battery_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>16/07/2019 9:00</td>\n",
       "      <td>806.834961</td>\n",
       "      <td>806.834961</td>\n",
       "      <td>2069.452637</td>\n",
       "      <td>2069.452637</td>\n",
       "      <td>135.575562</td>\n",
       "      <td>135.575562</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>16/07/2019 10:00</td>\n",
       "      <td>2289.109131</td>\n",
       "      <td>1482.274170</td>\n",
       "      <td>5071.029297</td>\n",
       "      <td>3001.576660</td>\n",
       "      <td>1358.957397</td>\n",
       "      <td>1223.381836</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>16/07/2019 11:00</td>\n",
       "      <td>3494.928711</td>\n",
       "      <td>1205.819580</td>\n",
       "      <td>7951.330078</td>\n",
       "      <td>2880.300781</td>\n",
       "      <td>2303.930176</td>\n",
       "      <td>944.972778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>16/07/2019 12:00</td>\n",
       "      <td>4859.251465</td>\n",
       "      <td>1364.322754</td>\n",
       "      <td>10781.760742</td>\n",
       "      <td>2830.430664</td>\n",
       "      <td>3256.703369</td>\n",
       "      <td>952.773193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>16/07/2019 13:00</td>\n",
       "      <td>6098.752930</td>\n",
       "      <td>1239.501465</td>\n",
       "      <td>13723.381836</td>\n",
       "      <td>2941.621094</td>\n",
       "      <td>4057.264160</td>\n",
       "      <td>800.560791</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_device              date        en_L1   cons_en_L1         en_L2  \\\n",
       "0         34   16/07/2019 9:00   806.834961   806.834961   2069.452637   \n",
       "1         34  16/07/2019 10:00  2289.109131  1482.274170   5071.029297   \n",
       "2         34  16/07/2019 11:00  3494.928711  1205.819580   7951.330078   \n",
       "3         34  16/07/2019 12:00  4859.251465  1364.322754  10781.760742   \n",
       "4         34  16/07/2019 13:00  6098.752930  1239.501465  13723.381836   \n",
       "\n",
       "    cons_en_L2        en_L3   cons_en_L3  en_L4  cons_en_L4  ...  min_THD_L4  \\\n",
       "0  2069.452637   135.575562   135.575562      0           0  ...           0   \n",
       "1  3001.576660  1358.957397  1223.381836      0           0  ...           0   \n",
       "2  2880.300781  2303.930176   944.972778      0           0  ...           0   \n",
       "3  2830.430664  3256.703369   952.773193      0           0  ...           0   \n",
       "4  2941.621094  4057.264160   800.560791      0           0  ...           0   \n",
       "\n",
       "   max_THD_L4  moy_THD_L4  min_THD_L5  max_THD_L5  moy_THD_L5  min_THD_L6  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   max_THD_L6  moy_THD_L6  battery_level  \n",
       "0           0           0              0  \n",
       "1           0           0              0  \n",
       "2           0           0              0  \n",
       "3           0           0              0  \n",
       "4           0           0              0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "filled-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in dataset.keys():\n",
    "    if len(dataset[k].value_counts()) <2:\n",
    "        dataset.drop(columns=[k], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "extra-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['date'] = pd.to_datetime(dataset['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "passing-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "round-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['year'] = data['date'].dt.year\n",
    "data['month'] = data['date'].dt.month\n",
    "data['day'] = data['date'].dt.day_name()\n",
    "data['hour'] = data['date'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "conscious-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cons_glbal'] = data['cons_en_L1'] + data['cons_en_L2'] + data['cons_en_L3'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "comprehensive-chrome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: 6948,\n",
       " 1: 6925,\n",
       " 12: 6819,\n",
       " 7: 6811,\n",
       " 11: 6753,\n",
       " 9: 6637,\n",
       " 8: 6468,\n",
       " 2: 6355,\n",
       " 3: 6133,\n",
       " 6: 4996,\n",
       " 5: 4705,\n",
       " 4: 4550}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months = dict(data[\"month\"].value_counts())\n",
    "months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "relative-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data, number_of_samples, number_of_result):\n",
    "    features = data['cons_glbal'].values.reshape(-1,1)\n",
    "    X, Y = [], []\n",
    "    list_months = list(data[\"month\"])\n",
    "    for month in months :\n",
    "        start_index = list_months.index(month)\n",
    "        for i in range (0,months[month]-number_of_samples,number_of_samples):\n",
    "            X.append(features[start_index+i:start_index+i+number_of_samples,0])\n",
    "            Y.append(features[start_index+i+number_of_samples:start_index+i+number_of_samples+number_of_result,0])\n",
    "\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "quality-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = transform_data(data, 50, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "neutral-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "stylish-atlanta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1476, 50)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "rotary-commons",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1476, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "boxed-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "Y = scaler2.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "august-maple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1476, 50, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = np.expand_dims(X_scaled, -1)\n",
    "X_scaled.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "interior-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size = 0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "equal-fabric",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58107929],\n",
       "       [0.57070444],\n",
       "       [0.63197824],\n",
       "       ...,\n",
       "       [0.54568109],\n",
       "       [0.50564403],\n",
       "       [0.67442857]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "conservative-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "occupational-dispute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 7s 126ms/step - loss: 0.1384 - val_loss: 0.0025\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 1s 34ms/step - loss: 0.0069 - val_loss: 0.0030\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 1s 35ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 1s 35ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 1s 34ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 1s 35ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 1s 35ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 1s 34ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 1s 35ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 1s 49ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 1s 48ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 1s 35ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 1s 37ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 1s 34ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 1s 34ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 30ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 1s 34ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 1s 35ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 1s 37ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.0017 - val_loss: 0.0027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bd310b5910>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(50,1), activation=\"tanh\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='MSE', optimizer='adam')\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test),epochs=100, batch_size=56, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "rubber-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../datasets/archive_en_p_mois.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fuzzy-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['cons_glbal'] = test['cons_en_L1'] + test['cons_en_L2'] + test['cons_en_L3'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "quality-intake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.764375e+06\n",
       "1      3.266888e+06\n",
       "2      3.037124e+06\n",
       "3      2.769838e+06\n",
       "4      2.355590e+06\n",
       "           ...     \n",
       "101    1.373240e+07\n",
       "102    1.408772e+07\n",
       "103    1.263620e+07\n",
       "104    1.160417e+07\n",
       "105    9.934701e+06\n",
       "Name: cons_glbal, Length: 106, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['cons_glbal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "grand-bridges",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predc  [[7146928.]]\n"
     ]
    }
   ],
   "source": [
    "test = test['cons_glbal']\n",
    "test\n",
    "\n",
    "x_input = np.array(test[0:50])\n",
    "input_MinMax = scaler.fit_transform(x_input.reshape(-1,1))\n",
    "input_MinMax = input_MinMax.reshape(1,50,  -1)\n",
    "x_itrainPredict = model.predict(input_MinMax)\n",
    "prediction = scaler.inverse_transform(x_itrainPredict)\n",
    "print('predc ',prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "defensive-calendar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0027\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "designing-wheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0027429526671767235"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "purple-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_determination"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
